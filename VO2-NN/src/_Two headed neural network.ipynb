{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.layers import Dense, Input,LSTM,Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from numpy import mean, std, absolute\n",
    "#Note: Use cross validation\n",
    "#, split data different test and train Random_state=None\n",
    "#(validation - small dataset)) Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[188.0, 78.4, 32, 'M', 17.58022, 163.5, 44.8475],\n",
       "       [175.0, 59.0, 22, 'F', 14.23946939, 189.4, 48.26938776],\n",
       "       [170.0, 58.1, 23, 'F', 12.08142149, 162.7, 41.58837],\n",
       "       [168.5, 54.0, 30, 'F', 12.1644882, 182.3, 45.05366],\n",
       "       [191.0, 98.6, 30, 'M', 19.5721, 198.5374064, 39.7],\n",
       "       [178.0, 63.0, 26, 'F', 13.34187855, 154.3, 42.35517],\n",
       "       [176.7, 82.0, 27, 'M', 16.0798105, 199.8, 39.21905],\n",
       "       [177.4, 66.3, 29, 'F', 14.25017724, 151.2, 42.986959999999996],\n",
       "       [162.6, 57.3, 25, 'F', 11.78905385, 173.35402130000003, 41.14853],\n",
       "       [178.0, 89.2, 27, 'M', 19.16277073, 186.5641757, 42.96585366],\n",
       "       [174.0, 67.5, 22, 'F', 12.91275, 168.46162980000003, 38.26],\n",
       "       [179.8, 73.9, 29, 'M', 15.81077937, 156.57106069999998, 42.78966],\n",
       "       [179.0, 79.0, 29, 'M', 16.50274845, 190.9, 41.779109999999996],\n",
       "       [168.8, 78.3, 23, 'F', 13.01552712, 175.84343909999998, 33.24528],\n",
       "       [175.1, 72.4, 29, 'F', 17.75458552, 188.66200569999998, 45.29231],\n",
       "       [182.0, 77.0, 34, 'M', 16.912102899999997, 188.8450593, 43.92754],\n",
       "       [187.5, 85.5, 34, 'M', 18.14679788, 152.75951630000003, 42.44865],\n",
       "       [164.8, 85.6, 30, 'M', 16.344036, 198.4, 38.187]], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq= pd.read_csv('Data.csv').values #data\n",
    "seq = np.array(seq)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning numerical values and storing in another column (Column Gender) 1 - Males, 0 - Females\n",
    "labelencoder = LabelEncoder() \n",
    "seq[:,3] = np.array(labelencoder.fit_transform(seq[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input1 (EE, HRmax) Time series data\n",
    "X1 = seq[:, 4:6]\n",
    "X1 = np.asarray(X1).astype(np.float32)\n",
    "X1 = X1.reshape((len(X1), 2, 1)) # Input 2 reshaped for LSTM \n",
    "# Input2 (Height, Age, Weight, Gender) and Output (VO2max)\n",
    "X, y = seq[:, 0:4], seq[:, 6] \n",
    "X = np.asarray(X).astype(np.float32)\n",
    "y = np.asarray(y).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 1) # splits data randomly everytime\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size = 0.33, random_state = 1) # splits data randomly everytime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input1 = Input(shape = (2,1)) #for time-series Input 1\n",
    "Input2 = Input(shape = (4,)) # for static Input 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left head Input 1 (x) Time series HR, EE\n",
    "lstm1 = LSTM(32,activation='elu', return_sequences = True)(Input1)\n",
    "lstm2=LSTM(16,activation='elu')(lstm1)\n",
    "x = tf.keras.Model(inputs=Input1, outputs=lstm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right head Input2 (y) \n",
    "dense1 = Dense(32 , kernel_initializer='normal', activation = 'elu')(Input2)\n",
    "dense2 = Dense(16, activation= 'elu', kernel_initializer='normal')(dense1)\n",
    "y = tf.keras.Model(inputs=Input2, outputs=dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# united Concatenate output of both heads\n",
    "united = tf.keras.layers.Concatenate()([x.output, y.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense3 = Dense(2, activation='elu')(united)\n",
    "z = Dense(1, activation=\"linear\")(dense3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[x.input, y.input], outputs=z)\n",
    "opt=Adam(learning_rate=0.02) # learning rate =0.02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 2/2500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 3/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 4/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 5/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 6/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 7/2500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 8/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 9/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 10/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 11/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 12/2500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 13/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 14/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 15/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 16/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 17/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 18/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 19/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 20/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 21/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 22/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 23/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 24/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 25/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 26/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 27/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 28/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 29/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 30/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 31/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 32/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 33/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 34/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 35/2500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 36/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 37/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 38/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 39/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 40/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 41/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 42/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 43/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 44/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 45/2500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 46/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 47/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 48/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 49/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 50/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 51/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 52/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 53/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 54/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 55/2500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 56/2500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 57/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 58/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 59/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 60/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 61/2500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 62/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 63/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 64/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 65/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 66/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 67/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 68/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 69/2500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 70/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 71/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 72/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 73/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 74/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 75/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 76/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 77/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 78/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 79/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 80/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 81/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 82/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 83/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 84/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 85/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 86/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 87/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 88/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 89/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 90/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 91/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 92/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 93/2500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 94/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 95/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 96/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 97/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 98/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 99/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 100/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 101/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 102/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 103/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 104/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 105/2500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 106/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 107/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 108/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 109/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 110/2500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.003 - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 111/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 112/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 113/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 114/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 115/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 116/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 117/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 118/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 119/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 120/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 121/2500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 122/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 123/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 124/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 125/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 126/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 127/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 128/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 129/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 130/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 131/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 132/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 133/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 134/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 135/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 136/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 137/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 138/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 139/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 140/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 141/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 142/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 143/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 144/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 145/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 146/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 147/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 148/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 149/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 150/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 151/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 152/2500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 153/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 154/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 155/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 156/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 157/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 158/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 159/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 160/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 161/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 162/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 163/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 164/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 165/2500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 166/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 167/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 168/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 169/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 170/2500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.003 - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 171/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 172/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 173/2500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 174/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 175/2500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.003 - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 176/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 177/2500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 178/2500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 179/2500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 180/2500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0113\n",
      "Epoch 181/2500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-6700c7facd25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean_squared_logarithmic_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1123\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1371\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1139\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[0;32m    694\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    720\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m    721\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_job_token\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         gen_experimental_dataset_ops.make_data_service_iterator(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3003\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3004\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3005\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3006\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MakeIterator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3007\u001b[0m         tld.op_callbacks, dataset, iterator)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model.compile(optimizer = opt, loss = 'mean_squared_logarithmic_error')\n",
    "model.fit([X1_train,X_train], y_train, epochs = 2500, batch_size=17, validation_data=([X1_test,X_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41.856583]\n",
      " [41.856583]\n",
      " [41.856583]\n",
      " [41.856583]\n",
      " [41.856583]\n",
      " [41.856583]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "yhat = model.predict([X1_test, X_test])\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualising the Actual and predicted Result\n",
    "plt.plot(y_test, color = 'green', label = 'Actual')\n",
    "plt.plot(yhat, color = 'blue', label = 'Predicted')\n",
    "plt.xlabel('Sample Number ')\n",
    "plt.ylabel('VO2max')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error:  17.414385\n",
      "r_square score:  -0.022994203364926857\n"
     ]
    }
   ],
   "source": [
    "print(\"mean squared error: \", mean_squared_error(y_test, yhat)) #compute MSE\n",
    "print(\"r_square score: \", r2_score(y_test, yhat)) # compute R2 score (accuracy for regression tasks or continuous data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_error:  2.6624477\n",
      "mean_error:  3.213371\n",
      "min_error:  0.26821136\n",
      "max_error:  8.611301\n"
     ]
    }
   ],
   "source": [
    "train_error =  np.abs(y_test - yhat)\n",
    "mean_error = np.mean(train_error)\n",
    "min_error = np.min(train_error)\n",
    "max_error = np.max(train_error)\n",
    "std_error = np.std(train_error)\n",
    "print(\"std_error: \",std_error)\n",
    "print(\"mean_error: \",mean_error)\n",
    "print(\"min_error: \",min_error)\n",
    "print(\"max_error: \",max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
